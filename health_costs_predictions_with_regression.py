# -*- coding: utf-8 -*-
"""fcc_predict_health_costs_with_regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/freeCodeCamp/boilerplate-linear-regression-health-costs-calculator/blob/master/fcc_predict_health_costs_with_regression.ipynb
"""

# Commented out IPython magic to ensure Python compatibility.
# Import libraries. 
!pip install -q git+https://github.com/tensorflow/docs
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers

import tensorflow_docs as tfdocs
import tensorflow_docs.plots
import tensorflow_docs.modeling

# Import data
!wget https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv
dataset = pd.read_csv('insurance.csv')
dataset.tail()

dataset_df=dataset
dataset_df

#Let's obtain some basic info about our dataset
dataset_df.describe()

dataset_df.info()

# Splitting our dataset into training and test set (test 20% of dataset size) 
from sklearn.model_selection import train_test_split

train_df,test_df=train_test_split(dataset_df,test_size=0.2,random_state=42)

print(train_df.shape)
print(test_df.shape)

# Identifying input and target(label)columns
input_cols=list(train_df)[:-1]
target_cols='expenses'

print(input_cols)

train_inputs=train_df[input_cols].copy()
train_targets=train_df[target_cols].copy()

test_inputs=test_df[input_cols].copy()
test_targets=test_df[target_cols].copy()

#Identifying numerical and categorical columns
numeric_cols= train_inputs.select_dtypes(include=np.number).columns.tolist()
categorical_cols=train_inputs.select_dtypes(include='object').columns.tolist()

#Let's scale our numeric columnss to make sure that there will not be a disproportional impact of a column in the training
from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()

scaler.fit(dataset_df[numeric_cols])

train_inputs[numeric_cols]=scaler.transform(train_inputs[numeric_cols])
test_inputs[numeric_cols]=scaler.transform(test_inputs[numeric_cols])


# Finally we need to perform OneHotEncoding to transform categorical data to numerical data
from sklearn.preprocessing import OneHotEncoder
encoder=OneHotEncoder(sparse=False, handle_unknown='ignore')

encoder.fit(dataset_df[categorical_cols])

encoded_cols = list(encoder.get_feature_names(categorical_cols))
print(encoded_cols)

train_inputs[encoded_cols]= encoder.transform(train_inputs[categorical_cols])
test_inputs[encoded_cols]= encoder.transform(test_inputs[categorical_cols])


X=train_inputs[numeric_cols+encoded_cols]
X_test=test_inputs[numeric_cols+encoded_cols]

model = keras.Sequential([
    keras.layers.Input(shape=(len(X.keys()),)),
    keras.layers.Dense(64,activation='relu'),
    keras.layers.Dense(32,activation='relu'),
    keras.layers.Dense(1)])

# Compiling the model
model.compile(optimizer='adam', loss='mse',metrics=['mae','mse'])
# Training the model
model.fit(X, train_targets, epochs=500)

#The model can also be trained using  XGBRegressor
***from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(random_state=42,n_jobs=-1,max_depth=10,n_estimators=20)

model.fit(X, train_targets)

preds = model.predict(X)
preds

from sklearn.metrics import mean_squared_error

def rmse(a, b):
    return mean_squared_error(a, b, squared=False)

rmse(preds,train_targets)

preds_test = model.predict(X_test)
#preds_test

rmse(preds_test,test_targets)

def test_params(**params):
    model = RandomForestRegressor( random_state=42, **params)
    model.fit(X, train_targets)
    train_rmse = rmse(model.predict(X), train_targets)
    test_rmse = rmse(model.predict(X_test), test_targets)
    print('Train RMSE: {}, Test RMSE: {}'.format(train_rmse, test_rmse))

test_params(n_estimators=10)***





# RUN THIS CELL TO TEST YOUR MODEL. DO NOT MODIFY CONTENTS.
# Test model by checking how well the model generalizes using the test set.
loss, mae, mse = model.evaluate(X_test, test_targets, verbose=2)

print("Testing set Mean Abs Error: {:5.2f} expenses".format(mae))

if mae < 3500:
  print("You passed the challenge. Great job!")
else:
  print("The Mean Abs Error must be less than 3500. Keep trying.")

# Plot predictions.
test_predictions = model.predict(X_test).flatten()

a = plt.axes(aspect='equal')
plt.scatter(test_targets, test_predictions)
plt.xlabel('True values (expenses)')
plt.ylabel('Predictions (expenses)')
lims = [0, 50000]
plt.xlim(lims)
plt.ylim(lims)
_ = plt.plot(lims,lims)